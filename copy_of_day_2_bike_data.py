# -*- coding: utf-8 -*-
"""Copy of Day 2 Bike Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AAnoKkJYMc3L0Nrggddj27ozDYJyQG4D
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

# import hour.csv
bikedf=pd.read_csv(r".\hour.csv")

numcols=bikedf[['temp', 'atemp', 'hum', 'windspeed','casual', 'registered',
                'cnt']]
objcols=bikedf[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',
       'workingday', 'weathersit']]

# Dependent Variable(y) is cnt (Total Count of Bicycles Rented)
# Build Machine Learning Model to predict "cnt" using all other variables as
# Independent Variables
# "cnt" is numerical and continuous, Regression Models to built

# Check for multicollinearity in numcols
# Distribution of "cnt"

# Check for multicollinearity in numcols - Correlation Analysis
import seaborn as sns
sns.heatmap(numcols.corr(),annot=True,cmap="plasma")
plt.show()

# Multicollinearity Present between temp & atemp, registered & cnt

# Distribution of cnt
fig,ax=plt.subplots(3,1)
sns.histplot(numcols['cnt'],ax=ax[0])
sns.boxplot(numcols['cnt'],ax=ax[1],orient="h")
sns.kdeplot(numcols['cnt'],ax=ax[2])
plt.show()

# Dummy Encode objcols
objcols_dummy=pd.get_dummies(objcols,columns=['season', 'yr', 'mnth', 'hr',
                                              'holiday', 'weekday',
                                              'workingday','weathersit'])
# Specify columns if data is int datatype but are categorical in nature

bikedf_final=pd.concat([numcols,objcols_dummy],axis=1)

# Split Data into y & X
y=bikedf_final.cnt
X=bikedf_final.drop('cnt',axis=1)

from sklearn.linear_model import LinearRegression

regmodel=LinearRegression().fit(X,y)

regmodel.score(X,y) # Overfitting due to multicollinearity

# Drop multicollinear columns
X_new=X.drop(['atemp','registered'],axis=1)

regmodel_new=LinearRegression().fit(X_new,y)

regmodel_new.score(X_new,y)

regmodel_new_pred=regmodel_new.predict(X_new)

from sklearn.metrics import root_mean_squared_error

root_mean_squared_error(y,regmodel_new_pred) # RMSE

# Build model with Log Transformation of y for positive skewness
regmodel_log=LinearRegression().fit(X_new,np.log(y))

regmodel_log.score(X_new,np.log(y))

regmodel_log_pred=regmodel_log.predict(X_new)

regmodel_log_pred=np.exp(regmodel_log_pred)

root_mean_squared_error(y,regmodel_log_pred)

